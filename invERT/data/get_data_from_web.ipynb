{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "from tarfile import open as taropen\n",
    "from tqdm import tqdm\n",
    "import gzip\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_url_from_thredds(\n",
    "        catalog_url: str,\n",
    "        model_tarname: str\n",
    "    )-> str:\n",
    "    \"\"\"Fetch the correct tar file URL from the THREDDS catalog.\"\"\"\n",
    "    response: requests.Response = requests.get(catalog_url)\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError(f\"Failed to access catalog: {catalog_url}\")\n",
    "\n",
    "    root: ET.Element = ET.fromstring(response.content)\n",
    "\n",
    "    # Define the namespace\n",
    "    namespace: dict[str, str] = {\"ns\": \"http://www.unidata.ucar.edu/namespaces/thredds/InvCatalog/v1.0\"}\n",
    "\n",
    "    # Find all dataset elements\n",
    "    datasets: list[ET.Element] = root.findall(\".//ns:dataset\", namespaces=namespace)\n",
    "\n",
    "    # Extract the URL path for each dataset\n",
    "    available_files: list[str] = [dataset.attrib.get(\"urlPath\", \"\") for dataset in datasets]\n",
    "\n",
    "    for url_path in available_files:\n",
    "        if model_tarname in url_path:  # Match the expected tar filename\n",
    "            return f\"https://thredds.nci.org.au/thredds/fileServer/{url_path}\"\n",
    "\n",
    "    raise ValueError(f\"File {model_tarname} not found in THREDDS catalog.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tar(\n",
    "        tar_url: str,\n",
    "        download_path: Path,\n",
    "        overwrite: bool = False,\n",
    "    ) -> Path | None:  \n",
    "    \"\"\"Download a tar file.\"\"\"\n",
    "    print(f\"Downloading tar file from {tar_url}\")\n",
    "\n",
    "    # Create the download path if it does not exist\n",
    "    try:\n",
    "        download_path.mkdir(parents=True, exist_ok=False)\n",
    "    except FileExistsError:\n",
    "        if not overwrite:\n",
    "            print(f\"Directory {download_path} already exists. To overwrite it, make sure to set the overwrite flag to True. If you don't want to overwrite, please provide a different path.\")\n",
    "            return None\n",
    "        else:\n",
    "            download_path.mkdir(parents=True, exist_ok=True)\n",
    "            print(f\"Successfully created directory {download_path}\")\n",
    "\n",
    "    # Download the tar file by chunks (large file)\n",
    "    response: requests.Response = requests.get(tar_url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # Downloaded file name\n",
    "    tar_filename: Path = download_path / Path(tar_url).name\n",
    "\n",
    "    total_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "    print(f\"Downloading to {tar_filename}\")\n",
    "\n",
    "    # Download the tar file by chunks of chunk_size bytes\n",
    "    with open(tar_filename, \"wb\") as file, tqdm(total=total_size, unit=\"B\", unit_scale=True, desc=\"Downloading\") as progress_bar:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            if chunk:\n",
    "                file.write(chunk)\n",
    "                progress_bar.update(len(chunk))\n",
    "                \n",
    "\n",
    "    return tar_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tar(\n",
    "        tar_filename: Path,\n",
    ") -> None:\n",
    "    # Extract contents\n",
    "    print(f\"Extracting tar file {tar_filename}\")\n",
    "    with taropen(tar_filename, \"r\") as tar:\n",
    "        members = tar.getmembers()\n",
    "        for member in tqdm(tar, desc=\"Extraction\", unit=\"file\", total=len(members)):\n",
    "            tar.extract(member, path=tar_filename.parent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(\n",
    "    tar_name: str,\n",
    "    extract_path: str,\n",
    "    catalog_url: str=\"https://thredds.nci.org.au/thredds/catalog/tm64/noddyverse/bulk_models/catalog.xml\",\n",
    "    overwrite: bool=False,\n",
    ") -> Path | None:\n",
    "    # 1. Get the tar file URL\n",
    "    tar_url: str = get_file_url_from_thredds(catalog_url, tar_name)\n",
    "    \n",
    "    # 2. Download and extract the tar file\n",
    "    tar_filename: Path | None = download_tar(tar_url, extract_path, overwrite=overwrite)\n",
    "\n",
    "    if tar_filename is None:\n",
    "        return None\n",
    "    \n",
    "    # 3. Extract the contents\n",
    "    print(f\"Extracting tar file {tar_filename}\")\n",
    "    extract_tar(tar_filename)\n",
    "    print(f\"Successfully extracted tar file {tar_filename}\")\n",
    "    return tar_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading tar file from https://thredds.nci.org.au/thredds/fileServer/tm64/noddyverse/bulk_models/UNCONFORMITY_PLUG_TILT.tar\n",
      "Successfully created directory ..\\..\\..\\dataset\\test\n",
      "Downloading to ..\\..\\..\\dataset\\test\\UNCONFORMITY_PLUG_TILT.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 550M/550M [00:36<00:00, 15.1MB/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tar file ..\\..\\..\\dataset\\test\\UNCONFORMITY_PLUG_TILT.tar\n",
      "Extracting tar file ..\\..\\..\\dataset\\test\\UNCONFORMITY_PLUG_TILT.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction: 100%|██████████| 5066/5066 [00:59<00:00, 85.20file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted tar file ..\\..\\..\\dataset\\test\\UNCONFORMITY_PLUG_TILT.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EVENTS: dict[int, str] = {\n",
    "    1: \"FOLD\",\n",
    "    2: \"FAULT\",\n",
    "    3: \"UNCONFORMITY\",\n",
    "    4: \"SHEAR-ZONE\",\n",
    "    5: \"DYKE\",\n",
    "    6: \"PLUG\",\n",
    "    7: \"TILT\",\n",
    "}\n",
    "events_list: list[int] = [3, 6, 7]\n",
    "events: str = f\"{EVENTS[events_list[0]]}_{EVENTS[events_list[1]]}_{EVENTS[events_list[2]]}\"\n",
    "tar_name: str = f\"{events}.tar\"\n",
    "\n",
    "dataset_folder: Path = Path(\"../../../dataset/test\")\n",
    "tar_filename: Path = get_subset(tar_name, dataset_folder, overwrite=True)  # Be careful, double check what you're doing if you use overwrite !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\..\\..\\dataset\\test\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(tar_filename\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m gzip\u001b[38;5;241m.\u001b[39mopen(tar_filename\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels_by_code/models\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m tar_filename\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m20-09-04-15-14-12-970750888.g00.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f_in:\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f_out:\n\u001b[0;32m      4\u001b[0m         shutil\u001b[38;5;241m.\u001b[39mcopyfileobj(f_in, f_out)\n",
      "File \u001b[1;32mc:\\Users\\gandon6u\\Documents\\labo3A\\invERT\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '.'"
     ]
    }
   ],
   "source": [
    "print(tar_filename.parent)\n",
    "with gzip.open(tar_filename.parent / \"models_by_code/models\" / tar_filename.name.split('.')[0] / \"20-09-04-15-14-12-970750888.g00.gz\", 'rb') as f_in:\n",
    "    with open(\".\", 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
